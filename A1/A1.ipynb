{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data scientists often need to crawl data from websites and turn the crawled data (HTML pages) to structured data (tables). Thus, web scraping is an essential skill that every data scientist should master. In this assignment, you will learn the followings:\n",
    "\n",
    "\n",
    "* How to download HTML pages from a website?\n",
    "* How to extract relevant content from an HTML page? \n",
    "\n",
    "Furthermore, you will gain a deeper understanding of the data science lifecycle.\n",
    "\n",
    "**Requirements:**\n",
    "\n",
    "1. Please use [pandas.DataFrame](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) rather than spark.DataFrame to manipulate data.\n",
    "\n",
    "2. Please use [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) rather than [lxml](http://lxml.de/) to parse an HTML page and extract data from the page.\n",
    "\n",
    "3. Please follow the python code style (https://www.python.org/dev/peps/pep-0008/). If TA finds your code hard to read, you will lose points. This requirement will stay for the whole semester."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this is your first time to write a web scraper, you need to learn some basic knowledge of this topic. I found that this is a good resource: [Tutorial: Web Scraping and BeautifulSoup](https://realpython.com/beautiful-soup-web-scraper-python/). \n",
    "\n",
    "Please let me know if you find a better resource. I'll share it with the other students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you are a data scientist working at HKUST(GZ). Your job is to extract insights from HKUST(GZ) data to answer questions. \n",
    "\n",
    "In this assignment, you will do two tasks. Please recall the high-level data science lifecycle from Lecture 1. I suggest that when doing this assignment, please remind yourself of what data you collected and what questions you tried to answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: HKUST(GZ) Information Hub Faculty Members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you don't know what questions to ask. No worries. Start collecting data first. \n",
    "\n",
    "In Task 1, your job is to write a web scraper to extract the faculty information from this page: [https://facultyprofiles.hkust-gz.edu.cn/](https://facultyprofiles.hkust-gz.edu.cn/).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Crawl Web Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A web page is essentially a file stored in a remote machine (called web server). Please write code to download the HTML page and save it as a text file (\"infhfaculty.html\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T16:15:23.442923Z",
     "start_time": "2023-09-11T16:15:23.439607Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML page saved as allinfhfaculty.html\n",
      "HTML page saved as infhfaculty1.html\n",
      "HTML page saved as infhfaculty2.html\n",
      "HTML page saved as infhfaculty3.html\n",
      "HTML page saved as infhfaculty4.html\n",
      "HTML page saved as infhfaculty5.html\n",
      "HTML page saved as infhfaculty6.html\n",
      "HTML page saved as infhfaculty7.html\n",
      "HTML page saved as infhfaculty8.html\n",
      "HTML page saved as infhfaculty9.html\n",
      "HTML page saved as infhfaculty10.html\n",
      "HTML page saved as infhfaculty11.html\n",
      "HTML page saved as infhfaculty12.html\n",
      "HTML page saved as infhfaculty13.html\n",
      "HTML page saved as infhfaculty14.html\n",
      "HTML page saved as infhfaculty15.html\n",
      "HTML page saved as infhfaculty16.html\n",
      "HTML page saved as infhfaculty17.html\n",
      "HTML page saved as infhfaculty18.html\n",
      "HTML page saved as infhfaculty19.html\n",
      "HTML page saved as infhfaculty20.html\n",
      "HTML page saved as infhfaculty21.html\n",
      "HTML page saved as infhfaculty22.html\n",
      "HTML page saved as infhfaculty23.html\n",
      "HTML page saved as infhfaculty24.html\n",
      "HTML page saved as infhfaculty25.html\n",
      "HTML page saved as infhfaculty26.html\n",
      "HTML page saved as infhfaculty27.html\n",
      "HTML page saved as infhfaculty28.html\n",
      "HTML page saved as infhfaculty29.html\n",
      "HTML page saved as infhfaculty30.html\n",
      "HTML page saved as infhfaculty31.html\n",
      "HTML page saved as infhfaculty32.html\n",
      "HTML page saved as infhfaculty33.html\n",
      "HTML page saved as infhfaculty34.html\n",
      "HTML page saved as infhfaculty35.html\n",
      "HTML page saved as infhfaculty36.html\n",
      "HTML page saved as infhfaculty37.html\n",
      "HTML page saved as infhfaculty38.html\n",
      "HTML page saved as infhfaculty39.html\n",
      "HTML page saved as infhfaculty40.html\n",
      "HTML page saved as infhfaculty41.html\n",
      "HTML page saved as infhfaculty42.html\n",
      "HTML page saved as infhfaculty43.html\n",
      "HTML page saved as infhfaculty44.html\n",
      "HTML page saved as infhfaculty45.html\n",
      "HTML page saved as infhfaculty46.html\n",
      "HTML page saved as infhfaculty47.html\n",
      "HTML page saved as infhfaculty48.html\n",
      "HTML page saved as infhfaculty49.html\n",
      "HTML page saved as infhfaculty50.html\n",
      "HTML page saved as infhfaculty51.html\n",
      "HTML page saved as infhfaculty52.html\n",
      "HTML page saved as infhfaculty53.html\n",
      "HTML page saved as infhfaculty54.html\n",
      "HTML page saved as infhfaculty55.html\n",
      "HTML page saved as infhfaculty56.html\n",
      "HTML page saved as infhfaculty57.html\n",
      "HTML page saved as infhfaculty58.html\n",
      "HTML page saved as infhfaculty59.html\n",
      "HTML page saved as infhfaculty60.html\n",
      "HTML page saved as infhfaculty61.html\n",
      "HTML page saved as infhfaculty62.html\n",
      "HTML page saved as infhfaculty63.html\n",
      "HTML page saved as infhfaculty64.html\n",
      "HTML page saved as infhfaculty65.html\n",
      "HTML page saved as infhfaculty66.html\n",
      "HTML page saved as infhfaculty67.html\n",
      "HTML page saved as infhfaculty68.html\n",
      "HTML page saved as infhfaculty69.html\n",
      "HTML page saved as infhfaculty70.html\n",
      "HTML page saved as infhfaculty71.html\n",
      "HTML page saved as infhfaculty72.html\n",
      "HTML page saved as infhfaculty73.html\n",
      "HTML page saved as infhfaculty74.html\n",
      "HTML page saved as infhfaculty75.html\n",
      "HTML page saved as infhfaculty76.html\n",
      "HTML page saved as infhfaculty77.html\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: \nStacktrace:\n0   chromedriver                        0x000000010489ed3c chromedriver + 4336956\n1   chromedriver                        0x0000000104896db8 chromedriver + 4304312\n2   chromedriver                        0x00000001044c3a5c chromedriver + 293468\n3   chromedriver                        0x0000000104508d50 chromedriver + 576848\n4   chromedriver                        0x0000000104543908 chromedriver + 817416\n5   chromedriver                        0x00000001044fca5c chromedriver + 526940\n6   chromedriver                        0x00000001044fd908 chromedriver + 530696\n7   chromedriver                        0x0000000104864d88 chromedriver + 4099464\n8   chromedriver                        0x0000000104869244 chromedriver + 4117060\n9   chromedriver                        0x000000010486f4d0 chromedriver + 4142288\n10  chromedriver                        0x0000000104869d44 chromedriver + 4119876\n11  chromedriver                        0x0000000104841a18 chromedriver + 3955224\n12  chromedriver                        0x00000001048869ec chromedriver + 4237804\n13  chromedriver                        0x0000000104886b68 chromedriver + 4238184\n14  chromedriver                        0x0000000104896a30 chromedriver + 4303408\n15  libsystem_pthread.dylib             0x00000001a6c27fa8 _pthread_start + 148\n16  libsystem_pthread.dylib             0x00000001a6c22da0 thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/Users/raymon/HKUSTGZ-DSAA5021/A1/A1.ipynb 单元格 12\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raymon/HKUSTGZ-DSAA5021/A1/A1.ipynb#X14sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, num_faculty\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raymon/HKUSTGZ-DSAA5021/A1/A1.ipynb#X14sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     more \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m//*[@id=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapp\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]/section/section/div/div[2]/div[3]/table/tbody/tr[\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(i)\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m]/td[6]/div/button\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/raymon/HKUSTGZ-DSAA5021/A1/A1.ipynb#X14sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     wait\u001b[39m.\u001b[39;49muntil(EC\u001b[39m.\u001b[39;49melement_to_be_clickable((By\u001b[39m.\u001b[39;49mXPATH,more)))\u001b[39m.\u001b[39mclick()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raymon/HKUSTGZ-DSAA5021/A1/A1.ipynb#X14sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     driver\u001b[39m.\u001b[39mswitch_to\u001b[39m.\u001b[39mwindow(driver\u001b[39m.\u001b[39mwindow_handles[\u001b[39m1\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/raymon/HKUSTGZ-DSAA5021/A1/A1.ipynb#X14sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     reaserch \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mel-tabs__item.is-top.is-active\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/scrab/lib/python3.9/site-packages/selenium/webdriver/support/wait.py:95\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[39mif\u001b[39;00m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m>\u001b[39m end_time:\n\u001b[1;32m     94\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[39mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: \nStacktrace:\n0   chromedriver                        0x000000010489ed3c chromedriver + 4336956\n1   chromedriver                        0x0000000104896db8 chromedriver + 4304312\n2   chromedriver                        0x00000001044c3a5c chromedriver + 293468\n3   chromedriver                        0x0000000104508d50 chromedriver + 576848\n4   chromedriver                        0x0000000104543908 chromedriver + 817416\n5   chromedriver                        0x00000001044fca5c chromedriver + 526940\n6   chromedriver                        0x00000001044fd908 chromedriver + 530696\n7   chromedriver                        0x0000000104864d88 chromedriver + 4099464\n8   chromedriver                        0x0000000104869244 chromedriver + 4117060\n9   chromedriver                        0x000000010486f4d0 chromedriver + 4142288\n10  chromedriver                        0x0000000104869d44 chromedriver + 4119876\n11  chromedriver                        0x0000000104841a18 chromedriver + 3955224\n12  chromedriver                        0x00000001048869ec chromedriver + 4237804\n13  chromedriver                        0x0000000104886b68 chromedriver + 4238184\n14  chromedriver                        0x0000000104896a30 chromedriver + 4303408\n15  libsystem_pthread.dylib             0x00000001a6c27fa8 _pthread_start + 148\n16  libsystem_pthread.dylib             0x00000001a6c22da0 thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "# write your code\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options = Options()\n",
    "#chrome_options.add_argument(\"--headless\")\n",
    "\n",
    "URL = \"https://facultyprofiles.hkust-gz.edu.cn\"\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)  # 实例化Chrome浏览器\n",
    "driver.get(URL) # 进入faculty列表\n",
    "\n",
    "wait = WebDriverWait(driver, 10, 0.5) # 设置等待时长\n",
    "info_button = '//*[@id=\"app\"]/section/section/div/ul[1]/li[3]' # 筛选Information Hub faculty\n",
    "wait.until(EC.element_to_be_clickable((By.XPATH,info_button))).click()\n",
    "\n",
    "last_faculty = '//*[@id=\"app\"]/section/section/div/div[2]/div[3]/table/tbody/tr[77]/td[6]/div/button'\n",
    "wait.until(EC.element_to_be_clickable((By.XPATH,last_faculty)))\n",
    "\n",
    "infhfaculty = driver.page_source\n",
    "\n",
    "file_name = \"infhfaculty/allinfhfaculty.html\" \n",
    "with open(file_name, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(infhfaculty)\n",
    "    \n",
    "print(\"HTML page saved as allinfhfaculty.html\")\n",
    "\n",
    "soup = BeautifulSoup(infhfaculty, 'html.parser')\n",
    "faculty_list = soup.find_all('div', class_='cell') #查找faculty信息\n",
    "faculty_list = [faculty.text for faculty in faculty_list] #将faculty_list转换为list格式的faculty\n",
    "\n",
    "num_faculty = len(faculty_list) // 6 - 1#观察faculty_list，发现每位教授有6个维度的信息，len//6-1则是教授的数量\n",
    "\n",
    "for i in range(1, num_faculty+1):\n",
    "    more = '//*[@id=\"app\"]/section/section/div/div[2]/div[3]/table/tbody/tr['+str(i)+']/td[6]/div/button'\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH,more))).click()\n",
    "    \n",
    "    driver.switch_to.window(driver.window_handles[1])\n",
    "        \n",
    "    reaserch = \"el-tabs__item.is-top.is-active\"\n",
    "    wait.until(EC.element_to_be_clickable((By.CLASS_NAME,reaserch))).click()\n",
    "    \n",
    "    infhfaculty =driver.page_source\n",
    "    \n",
    "    file_name = \"infhfaculty/infhfaculty\"+str(i)+\".html\"\n",
    "    with open(file_name, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(infhfaculty)\n",
    "    \n",
    "    print(\"HTML page saved as infhfaculty\"+str(i)+\".html\") \n",
    "    \n",
    "    driver.close()\n",
    "    driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Extract Structured Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please write code to extract relevant content (name, rank, area, profile, homepage, ...) from \"infhfaculty.html\" and save them as a CSV file (save as \"faculty_table.csv\"). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-11T16:19:55.088770Z",
     "start_time": "2023-09-11T16:19:55.083561Z"
    }
   },
   "outputs": [],
   "source": [
    "# write your code\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "file_name = 'infhfaculty.html'\n",
    "\n",
    "with open(file_name, 'r', encoding='utf-8') as file: # 打开html文件\n",
    "    html_content = file.read()\n",
    "\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "faculty_list = soup.find_all('div', class_='cell') #查找faculty信息\n",
    "faculty_list = [faculty.text for faculty in faculty_list] #将faculty_list转换为list格式的faculty\n",
    "\n",
    "num_faculty = len(faculty_list) // 6 - 1#观察faculty_list，发现每位教授有6个维度的信息，len//6-1则是教授的数量\n",
    "data_reshaped = pd.DataFrame(pd.Series(faculty_list).values.reshape(num_rows, -1)) #将数据按顺序分为6列放入dataframe中\n",
    "faculty_table = data_reshaped.drop(5, axis=1) #drop多余的“more”列\n",
    "faculty_table.columns = list(faculty_table.iloc[0,:]) #更改列名\n",
    "faculty_table = faculty_table.drop(0, axis=0) #drop第一行维度信息\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "file_name = 'infhfaculty.html'\n",
    "driver.get(file_name)\n",
    "#wait = WebDriverWait(driver, 10)\n",
    "more = '//*[@id=\"app\"]/section/section/div/div[2]/div[3]/table/tbody/tr['+str(1)+']/td[6]/div/button'\n",
    "#wait.until(EC.element_to_be_clickable(By.XPATH, more)).click()\n",
    "EC.element_to_be_clickable(By.XPATH, more).click()\n",
    "driver.switch_to.window(driver.window_handles[i])\n",
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"el-row\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#wait = WebDriverWait(driver, 10)\n",
    "#num_faculty = faculty_table.shape[0]\n",
    "\n",
    "for i in range(1,num_faculty):\n",
    "    more = '//*[@id=\"app\"]/section/section/div/div[2]/div[3]/table/tbody/tr['+str(i)+']/td[6]/div/button'\n",
    "    wait.until(EC.element_to_be_clickable((By.XPATH, more))).click()\n",
    "    driver.switch_to.window(driver.window_handles[i])\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"el-row\")))\n",
    "\n",
    "faculty_table.to_csv('faculty_table.csv', encoding='utf-8_sig') #导出文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faculty_table.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Interesting Finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you don't need to do anything for Task 1(c). The purpose of this part is to give you some sense about how to leverage Exploratory Data Analysis (EDA) to come up with interesting questions about the data. EDA is an important topic in data science; you will  learn it soon from this course. \n",
    "\n",
    "\n",
    "First, please install [dataprep](http://dataprep.ai).\n",
    "Then, run the cell below. \n",
    "It shows a bar chart for every column. What interesting findings can you get from these visualizations? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install dataprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprep.eda import plot\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"faculty_table.csv\")\n",
    "plot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some examples:\n",
    "\n",
    "**Finding 1:** Assistant Professor# (~76) is more than 5x larger than Associate Professor# (10). \n",
    "\n",
    "**Questions:** Why did it happen? Is it common in all CS schools in the world? Will the gap go larger or smaller in five years? What actions can be taken to enlarge/shrink the gap?\n",
    "\n",
    "\n",
    "**Finding 2:** The Homepage has 22% missing values. \n",
    "\n",
    "**Questions:** Why are there so many missing values? Is it because many faculty do not have their own homepages or do not add their homepages to the school page? What actions can be taken to avoid this to happen in the future? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Age Follows Normal Distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you start with a question and then figure out what data to collect.\n",
    "\n",
    "The question that you are interested in is `Does HKUST(GZ) Info Hub faculty age follow a normal distribution?`\n",
    "\n",
    "To estimate the age of a faculty member, you can collect the year in which s/he graduates from a university (`gradyear`) and then estimate `age` using the following equation:\n",
    "\n",
    "$$age \\approx 2023+23 - gradyear$$\n",
    "\n",
    "For example, if one graduates from a university in 1990, then the age is estimated as 2023+23-1990 = 56. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Crawl Web Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You notice that faculty profile pages contain graduation information. For example, you can see that Dr. Yuyu LUO graduated from Tsinghua University in 2023 at [https://facultyprofiles.hkust-gz.edu.cn/faculty-personal-page/LUO-Yuyu/yuyuluo](https://facultyprofiles.hkust-gz.edu.cn/faculty-personal-page/LUO-Yuyu/yuyuluo). \n",
    "\n",
    "\n",
    "Please write code to download the profile pages (info hub faculties) and save each page as a text file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Extract Structured Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please write code to extract the earliest graduation year (e.g., 2023 for Dr. Yuyu LUO) from each profile page, and create a csv file like [faculty_grad_year.csv](./faculty_grad_year.csv). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Interesting Finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to Task 1(c), you don't need to do anything here. Just look at different visualizations w.r.t. age and give yourself an answer to the question: `Does HKUST(GZ) Info Hub faculty age follow a normal distribution?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dataprep.eda import plot\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"faculty_grad_year.csv\")\n",
    "df[\"age\"] = 2023+23-df[\"gradyear\"]\n",
    "\n",
    "plot(df, \"age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the code in this notebook, and submit it to the Canvas assignment `Assignment 1`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
